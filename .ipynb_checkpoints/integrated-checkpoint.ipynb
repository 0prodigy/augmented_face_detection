{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab5b8f1-dd0c-4560-a914-7899246fe76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import cv2\n",
    "import imutils\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.utils import decode_predictions\n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62fbf56e-52f0-40f5-8290-3580b8f36b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'face': <CascadeClassifier 0x7fe4f5209c50>, 'eyes': <CascadeClassifier 0x7fe4f5a98410>, 'smile': <CascadeClassifier 0x7fe4fbe294d0>}\n"
     ]
    }
   ],
   "source": [
    "detectorPaths = {\n",
    "\t\"face\": \"haarcascade_frontalface_default.xml\",\n",
    "\t\"eyes\": \"haarcascade_eye.xml\",\n",
    "\t\"smile\": \"haarcascade_smile.xml\",\n",
    "}\n",
    "\n",
    "detector = {}\n",
    "\n",
    "for (name,path) in detectorPaths.items():\n",
    "    path = os.path.join(\"./haarcascades/\",path)\n",
    "    detector[name] = cv2.CascadeClassifier(path)\n",
    "\n",
    "print(detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32281e62-0130-4bab-8d5b-2a3d2e9628e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start video stream\n",
    "model = VGGFace(model= 'resnet50')\n",
    "# detector = MTCNN()\n",
    "target_size = (224,224) # output image size\n",
    "border_rel = 0 # increase or decrease zoom on image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ba9208-9cd6-4ce0-9787-0490170167fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "cv2.startWindowThread()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06912a66-f0b3-4cad-b69d-71ea337be1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(img):\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "#     img_target = cv2.imread(\"test2.jpg\")\n",
    "    img_target = img\n",
    "    temp_video = cv2.VideoCapture(\"test.mov\")\n",
    "\n",
    "\n",
    "    detection = False\n",
    "    frame_counter = 0\n",
    "\n",
    "    success, imgVideo = temp_video.read()\n",
    "    hT,wT,cT = img_target.shape\n",
    "    imgVideo = cv2.resize(imgVideo,(wT,hT))\n",
    "\n",
    "\n",
    "\n",
    "    orb = cv2.ORB_create(nfeatures=1000)\n",
    "    kp1, des1 = orb.detectAndCompute(img_target,None)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        success, img_web_cam = cap.read()\n",
    "        img_aug = img_web_cam.copy()\n",
    "        kp2, des2 = orb.detectAndCompute(img_web_cam,None)\n",
    "\n",
    "\n",
    "    #     img_web_cam = cv2.drawKeypoints(img_web_cam,kp2,None) \n",
    "\n",
    "        if detection == False:\n",
    "            temp_video.set(cv2.CAP_PROP_POS_FRAMES,0)\n",
    "            frame_counter = 0\n",
    "        else: \n",
    "            if frame_counter == temp_video.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "                temp_video.set(cv2.CAP_PROP_POS_FRAMES,0)\n",
    "                frame_counter = 0\n",
    "            success, imgVideo = temp_video.read()\n",
    "            imgVideo = cv2.resize(imgVideo,(wT,hT))\n",
    "\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1,des2,k=2)\n",
    "        good = []\n",
    "\n",
    "\n",
    "\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append(m)\n",
    "\n",
    "\n",
    "        if len(good) > 20:\n",
    "            detection = True\n",
    "\n",
    "            srcPts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "            dstPts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "            matrix, mask = cv2.findHomography(srcPts,dstPts,cv2.RANSAC,5)\n",
    "\n",
    "\n",
    "            pts = np.float32([[0,0],[0,hT],[wT,hT],[wT,0]]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts,matrix)\n",
    "\n",
    "            img2 = cv2.polylines(img_web_cam,[np.int32(dst)],True,(225,0,225),3)\n",
    "\n",
    "            imgWrap = cv2.warpPerspective(imgVideo,matrix,(img_web_cam.shape[1],img_web_cam.shape[0]))\n",
    "\n",
    "            mask_new = np.zeros((img_web_cam.shape[0],img_web_cam.shape[1]),np.uint8)\n",
    "\n",
    "            cv2.fillPoly(mask_new,[np.int32(dst)],(225,225,255))\n",
    "            maskInv = cv2.bitwise_not(mask_new)\n",
    "            img_aug = cv2.bitwise_and(img_aug,img_aug,mask=maskInv)\n",
    "            img_aug = cv2.bitwise_or(imgWrap,img_aug)\n",
    "\n",
    "    #         cv2.imshow(\"imgWrap\",img_aug)\n",
    "\n",
    "            cv2.fillConvexPoly(mask_new, dst.astype(\"int32\"), (255, 255, 255),cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            rect = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "            mask = cv2.dilate(mask_new, rect, iterations=2)\n",
    "\n",
    "\n",
    "            maskScaled = mask_new.copy() / 255.0\n",
    "            maskScaled = np.dstack([maskScaled] * 3)\n",
    "\n",
    "\n",
    "            warpedMultiplied = cv2.multiply(imgWrap.astype(\"float\"), maskScaled)\n",
    "            imageMultiplied = cv2.multiply(img_aug.astype(float), 1.0 - maskScaled)\n",
    "            output = cv2.add(warpedMultiplied, imageMultiplied)\n",
    "            output = output.astype(\"uint8\")\n",
    "\n",
    "            cv2.imshow(\"output\",output)\n",
    "\n",
    "        img_features = cv2.drawMatches(img_target,kp1,img_web_cam,kp2,good,None,flags=2)\n",
    "\n",
    "\n",
    "\n",
    "    #     cv2.imshow(\"feature\",img_features)\n",
    "    #     cv2.imshow(\"target_image\", img_target)\n",
    "\n",
    "        cv2.imshow(\"webcam\", img_web_cam)\n",
    "    #     cv2.imshow(\"video\", imgVideo)\n",
    "        frame_counter += 1\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08923a07-0c68-448f-9eb4-7b6caa62b017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' Channing_Tatum': 99.713%\n",
      "b' Vince_Gill': 0.011%\n",
      "b' Jesse_Palmer': 0.009%\n",
      "b' Ronnie_Ortiz-Magro': 0.008%\n",
      "b' Imanol_Harinordoquy': 0.005%\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame,width=500)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    face_rect = detector[\"face\"].detectMultiScale(gray,scaleFactor=1.05, minNeighbors=5, minSize=(30, 30),\n",
    "                                                  flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (fX, fY, fW, fH) in face_rect:\n",
    "        \n",
    "        cv2.rectangle(gray,(fX, fY), (fX + fW, fY + fH),\n",
    "                      (0, 255, 0), 2)\n",
    "        \n",
    "        x1, y1, width, height = fX, fY, fW, fH\n",
    "        dw = round(width * border_rel)\n",
    "        dh = round(height * border_rel)\n",
    "\n",
    "        x2, y2 = x1 + width + dw, y1 + height + dh\n",
    "#         face = frame[y1:y2, x1:x2]\n",
    "        \n",
    "#         faces = frame[fY : fY + fH , fX:fX + fW]\n",
    "#         cv2.imshow(\"faces\",faces)\n",
    "    \n",
    "    \n",
    "        \n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        face = PIL.Image.fromarray(face)\n",
    "        face = face.resize((224, 224))\n",
    "        face = np.asarray(face)\n",
    "\n",
    " \n",
    "        face_pp = face.astype('float32')\n",
    "        face_pp = np.expand_dims(face_pp, axis = 0)\n",
    "        face_pp = preprocess_input(face_pp, version = 2)\n",
    "    \n",
    "        prediction = model.predict(face_pp)\n",
    "        results = decode_predictions(prediction)\n",
    "        \n",
    "        # Display results\n",
    "        cv2.imshow(\"face\",face)\n",
    "        \n",
    "        if(results[0][0][1] * 100 > 90):\n",
    "            \n",
    "            ans = input()\n",
    "            play_video(face)\n",
    "            \n",
    "            for result in results[0]:\n",
    "                print ('%s: %.3f%%' % (result[0], result[1]*100))\n",
    "    \n",
    "    cv2.imshow(\"Frame\", gray)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30a1df-e9ee-46c5-ba3b-c9f54c25ccf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
